{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f10735-05e9-4cf0-8f77-f2e4aa572b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - C:\\Users\\tozes\\Documents\\IronHack\\pl_21-25_analysis\\data_processed\\sql_model\\dim_season.csv\n",
      " - C:\\Users\\tozes\\Documents\\IronHack\\pl_21-25_analysis\\data_processed\\sql_model\\dim_team.csv\n",
      " - C:\\Users\\tozes\\Documents\\IronHack\\pl_21-25_analysis\\data_processed\\sql_model\\dim_match.csv\n",
      " - C:\\Users\\tozes\\Documents\\IronHack\\pl_21-25_analysis\\data_processed\\sql_model\\fact_team_match.csv\n",
      "\n",
      "Counts:\n",
      "dim_season: 4\n",
      "dim_team: 26\n",
      "dim_match: 1520\n",
      "fact_team_match: 3040\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 0) Paths (robust if you run from /notebooks)\n",
    "# -------------------------\n",
    "cwd = Path.cwd()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name.lower() == \"notebooks\" else cwd\n",
    "\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "OUT_DIR = DATA_PROCESSED / \"sql_model\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_PATH = DATA_PROCESSED / \"pl_master_21-25_v1.csv\"\n",
    "if not MASTER_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Master file not found: {MASTER_PATH.resolve()}\")\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load master\n",
    "# -------------------------\n",
    "df = pd.read_csv(MASTER_PATH)\n",
    "\n",
    "# Ensure Date is parsed consistently (your data is already yyyy-mm-dd, this just makes it explicit)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) dim_season\n",
    "# -------------------------\n",
    "seasons = sorted(df[\"Season\"].dropna().unique())\n",
    "dim_season = pd.DataFrame({\"season\": seasons})\n",
    "dim_season[\"season_id\"] = range(1, len(dim_season) + 1)\n",
    "dim_season = dim_season[[\"season_id\", \"season\"]]\n",
    "\n",
    "season_map = dict(zip(dim_season[\"season\"], dim_season[\"season_id\"]))\n",
    "\n",
    "# -------------------------\n",
    "# 3) dim_team (union across all relevant team columns)\n",
    "# -------------------------\n",
    "team_cols = [\"Team\", \"home_team\", \"away_team\", \"opponent\"]\n",
    "all_teams = pd.unique(pd.concat([df[c].dropna().astype(str) for c in team_cols], ignore_index=True))\n",
    "all_teams = sorted(all_teams)\n",
    "\n",
    "dim_team = pd.DataFrame({\"team_name\": all_teams})\n",
    "dim_team[\"team_id\"] = range(1, len(dim_team) + 1)\n",
    "dim_team = dim_team[[\"team_id\", \"team_name\"]]\n",
    "\n",
    "team_map = dict(zip(dim_team[\"team_name\"], dim_team[\"team_id\"]))\n",
    "\n",
    "# -------------------------\n",
    "# 4) dim_match (1 row per match_id)\n",
    "# -------------------------\n",
    "dim_match = (\n",
    "    df[[\"match_id\", \"Season\", \"Date\", \"home_team\", \"away_team\", \"home_goals\", \"away_goals\"]]\n",
    "    .drop_duplicates(\"match_id\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "dim_match[\"season_id\"] = dim_match[\"Season\"].map(season_map).astype(\"int64\")\n",
    "dim_match[\"home_team_id\"] = dim_match[\"home_team\"].astype(str).map(team_map).astype(\"int64\")\n",
    "dim_match[\"away_team_id\"] = dim_match[\"away_team\"].astype(str).map(team_map).astype(\"int64\")\n",
    "\n",
    "dim_match[\"match_date\"] = dim_match[\"Date\"].dt.date\n",
    "dim_match[\"match_label\"] = (\n",
    "    dim_match[\"home_team\"].astype(str)\n",
    "    + \" \"\n",
    "    + dim_match[\"home_goals\"].astype(str)\n",
    "    + \"-\"\n",
    "    + dim_match[\"away_goals\"].astype(str)\n",
    "    + \" \"\n",
    "    + dim_match[\"away_team\"].astype(str)\n",
    ")\n",
    "\n",
    "dim_match = dim_match[\n",
    "    [\"match_id\", \"season_id\", \"match_date\", \"home_team_id\", \"away_team_id\", \"home_goals\", \"away_goals\", \"match_label\"]\n",
    "].sort_values([\"season_id\", \"match_date\", \"match_id\"])\n",
    "\n",
    "# -------------------------\n",
    "# 5) fact_team_match (1 row per team per match)\n",
    "# -------------------------\n",
    "fact = df.copy()\n",
    "\n",
    "fact[\"season_id\"] = fact[\"Season\"].map(season_map).astype(\"int64\")\n",
    "fact[\"team_id\"] = fact[\"Team\"].astype(str).map(team_map).astype(\"int64\")\n",
    "fact[\"opponent_team_id\"] = fact[\"opponent\"].astype(str).map(team_map).astype(\"int64\")\n",
    "\n",
    "# Convert boolean to int (SQL-friendly)\n",
    "fact[\"is_home\"] = fact[\"is_home\"].astype(int)\n",
    "\n",
    "# Drop redundant string columns that will live in dimensions\n",
    "# (keep match_id + keys + metrics)\n",
    "drop_cols = [\"Season\", \"Team\", \"opponent\", \"home_team\", \"away_team\", \"Match\", \"Date\"]\n",
    "fact = fact.drop(columns=[c for c in drop_cols if c in fact.columns])\n",
    "\n",
    "# Reorder: keys first\n",
    "key_cols = [\"match_id\", \"season_id\", \"team_id\", \"opponent_team_id\", \"is_home\"]\n",
    "other_cols = [c for c in fact.columns if c not in key_cols]\n",
    "fact = fact[key_cols + other_cols]\n",
    "\n",
    "# -------------------------\n",
    "# 6) Quick validations vs master expectations\n",
    "# -------------------------\n",
    "assert len(df) == 3040, f\"Expected 3040 rows in master, got {len(df)}\"\n",
    "assert len(dim_match) == 1520, f\"Expected 1520 unique matches, got {len(dim_match)}\"\n",
    "assert len(fact) == 3040, f\"Fact should have same rows as master, got {len(fact)}\"\n",
    "assert fact[[\"match_id\", \"team_id\"]].duplicated().sum() == 0, \"Duplicate (match_id, team_id) found in fact!\"\n",
    "\n",
    "# -------------------------\n",
    "# 7) Save outputs (CSV) to load into SQL easily\n",
    "# -------------------------\n",
    "dim_season.to_csv(OUT_DIR / \"dim_season.csv\", index=False, encoding=\"utf-8\")\n",
    "dim_team.to_csv(OUT_DIR / \"dim_team.csv\", index=False, encoding=\"utf-8\")\n",
    "dim_match.to_csv(OUT_DIR / \"dim_match.csv\", index=False, encoding=\"utf-8\")\n",
    "fact.to_csv(OUT_DIR / \"fact_team_match.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" -\", (OUT_DIR / \"dim_season.csv\").resolve())\n",
    "print(\" -\", (OUT_DIR / \"dim_team.csv\").resolve())\n",
    "print(\" -\", (OUT_DIR / \"dim_match.csv\").resolve())\n",
    "print(\" -\", (OUT_DIR / \"fact_team_match.csv\").resolve())\n",
    "\n",
    "print(\"\\nCounts:\")\n",
    "print(\"dim_season:\", len(dim_season))\n",
    "print(\"dim_team:\", len(dim_team))\n",
    "print(\"dim_match:\", len(dim_match))\n",
    "print(\"fact_team_match:\", len(fact))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34ef954-a59f-4d21-908d-0a29d0936c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS `fact_team_match`;\n",
      "\n",
      "CREATE TABLE `fact_team_match` (\n",
      "  `match_id` VARCHAR(120) NOT NULL,\n",
      "  `season_id` INT NOT NULL,\n",
      "  `team_id` INT NOT NULL,\n",
      "  `opponent_team_id` INT NOT NULL,\n",
      "  `is_home` TINYINT NOT NULL,\n",
      "  `xG` DOUBLE,\n",
      "  `xGA` DOUBLE,\n",
      "  `xGD` DOUBLE,\n",
      "  `Open Play xG` DOUBLE,\n",
      "  `Open Play xGA` DOUBLE,\n",
      "  `Open Play xGD` DOUBLE,\n",
      "  `Set Piece xG` DOUBLE,\n",
      "  `Set Piece xGA` DOUBLE,\n",
      "  `Set Piece xGD` DOUBLE,\n",
      "  `npxG` DOUBLE,\n",
      "  `npxGA` DOUBLE,\n",
      "  `npxGD` DOUBLE,\n",
      "  `Goals` INT,\n",
      "  `Goals Conceded` INT,\n",
      "  `GD` INT,\n",
      "  `GD-xGD` DOUBLE,\n",
      "  `Possession` DOUBLE,\n",
      "  `Field Tilt` DOUBLE,\n",
      "  `Avg Pass Height` DOUBLE,\n",
      "  `xT` DOUBLE,\n",
      "  `xT Against` DOUBLE,\n",
      "  `Passes in Opposition Half` INT,\n",
      "  `Passes into Box` INT,\n",
      "  `Shots` INT,\n",
      "  `Shots Faced` INT,\n",
      "  `Shots per 1.0 xT` DOUBLE,\n",
      "  `Shots Faced per 1.0 xT Against` DOUBLE,\n",
      "  `PPDA` DOUBLE,\n",
      "  `High Recoveries` INT,\n",
      "  `High Recoveries Against` INT,\n",
      "  `Crosses` INT,\n",
      "  `Corners` INT,\n",
      "  `Fouls` INT,\n",
      "  `On-Ball Pressure` DOUBLE,\n",
      "  `On-Ball Pressure Share` DOUBLE,\n",
      "  `Off-Ball Pressure` DOUBLE,\n",
      "  `Off-Ball Pressure Share` DOUBLE,\n",
      "  `Game Control` DOUBLE,\n",
      "  `Game Control Share` DOUBLE,\n",
      "  `Throw-Ins into the Box` INT,\n",
      "  `home_goals` INT,\n",
      "  `away_goals` INT,\n",
      "  `goals_for` INT,\n",
      "  `goals_against` INT,\n",
      "  `result` CHAR(1),\n",
      "  `points` INT,\n",
      "  `xT_diff` DOUBLE,\n",
      "  `shot_quality` DOUBLE,\n",
      "  `shot_quality_conceded` DOUBLE,\n",
      "  PRIMARY KEY (`match_id`, `team_id`),\n",
      "  INDEX `idx_ftm_season` (`season_id`),\n",
      "  INDEX `idx_ftm_team` (`team_id`),\n",
      "  INDEX `idx_ftm_opponent` (`opponent_team_id`),\n",
      "  CONSTRAINT `fk_ftm_match` FOREIGN KEY (`match_id`) REFERENCES `dim_match`(`match_id`),\n",
      "  CONSTRAINT `fk_ftm_season` FOREIGN KEY (`season_id`) REFERENCES `dim_season`(`season_id`),\n",
      "  CONSTRAINT `fk_ftm_team` FOREIGN KEY (`team_id`) REFERENCES `dim_team`(`team_id`),\n",
      "  CONSTRAINT `fk_ftm_opponent` FOREIGN KEY (`opponent_team_id`) REFERENCES `dim_team`(`team_id`)\n",
      ") ENGINE=InnoDB;\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- paths (assumindo notebook em /notebooks) ---\n",
    "csv_path = Path(\"..\") / \"data_processed\" / \"sql_model\" / \"fact_team_match.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def max_len(s: pd.Series) -> int:\n",
    "    s = s.dropna().astype(str)\n",
    "    return int(s.map(len).max()) if len(s) else 1\n",
    "\n",
    "def mysql_type(col: str, s: pd.Series) -> str:\n",
    "    # regras \"fortes\" primeiro\n",
    "    if col == \"match_id\":\n",
    "        return \"VARCHAR(120)\"\n",
    "    if col in {\"result\"}:\n",
    "        return \"CHAR(1)\"\n",
    "    if col in {\"is_home\"}:\n",
    "        return \"TINYINT\"\n",
    "    if col.lower().endswith(\"_id\"):\n",
    "        return \"INT\"\n",
    "    if col.lower() == \"date\":\n",
    "        return \"DATE\"\n",
    "\n",
    "    # inferência por dtype\n",
    "    if pd.api.types.is_integer_dtype(s):\n",
    "        return \"INT\"\n",
    "    if pd.api.types.is_float_dtype(s):\n",
    "        return \"DOUBLE\"\n",
    "\n",
    "    # strings\n",
    "    l = max_len(s)\n",
    "    return f\"VARCHAR({min(max(l, 1), 255)})\" if l <= 255 else \"TEXT\"\n",
    "\n",
    "# colunas NOT NULL (chaves)\n",
    "not_null_cols = {\"match_id\", \"season_id\", \"team_id\", \"opponent_team_id\", \"is_home\"}\n",
    "\n",
    "lines = []\n",
    "for col in df.columns:\n",
    "    col_sql = f\"`{col}`\"  # backticks para nomes com espaços/pontos\n",
    "    t = mysql_type(col, df[col])\n",
    "    nn = \" NOT NULL\" if col in not_null_cols else \"\"\n",
    "    lines.append(f\"  {col_sql} {t}{nn}\")\n",
    "\n",
    "ddl = f\"\"\"\n",
    "DROP TABLE IF EXISTS `fact_team_match`;\n",
    "\n",
    "CREATE TABLE `fact_team_match` (\n",
    "{\",\\n\".join(lines)},\n",
    "  PRIMARY KEY (`match_id`, `team_id`),\n",
    "  INDEX `idx_ftm_season` (`season_id`),\n",
    "  INDEX `idx_ftm_team` (`team_id`),\n",
    "  INDEX `idx_ftm_opponent` (`opponent_team_id`),\n",
    "  CONSTRAINT `fk_ftm_match` FOREIGN KEY (`match_id`) REFERENCES `dim_match`(`match_id`),\n",
    "  CONSTRAINT `fk_ftm_season` FOREIGN KEY (`season_id`) REFERENCES `dim_season`(`season_id`),\n",
    "  CONSTRAINT `fk_ftm_team` FOREIGN KEY (`team_id`) REFERENCES `dim_team`(`team_id`),\n",
    "  CONSTRAINT `fk_ftm_opponent` FOREIGN KEY (`opponent_team_id`) REFERENCES `dim_team`(`team_id`)\n",
    ") ENGINE=InnoDB;\n",
    "\"\"\".strip()\n",
    "\n",
    "print(ddl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e1a06-3e0e-46b8-8a90-92b97e42b39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Scraping)",
   "language": "python",
   "name": "scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
